{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarceloNevesDS/MarceloNevesDS/blob/main/C%C3%B3pia_de_Damos_lhe_as_boas_vindas_ao_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar as dependencias\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
        "\n",
        "!tar xf spark-3.3.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "7xBPMZvr7Fl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar as variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\"\n",
        "\n",
        "# Torna PySpark \"importável\"\n",
        "import findspark\n",
        "findspark.init('spark-3.3.0-bin-hadoop3')\n"
      ],
      "metadata": {
        "id": "om_xjyKx8gF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /usr/lib/jvm/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4pP3vOoFUnt",
        "outputId": "2308fc7f-c5c6-4507-9162-3ec4a978de26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28\n",
            "drwxr-xr-x 1 root root 4096 Sep 19 18:20 .\n",
            "drwxr-xr-x 1 root root 4096 Sep 14 13:37 ..\n",
            "lrwxrwxrwx 1 root root   25 Feb 20  2019 default-java -> java-1.11.0-openjdk-amd64\n",
            "lrwxrwxrwx 1 root root   21 Jul 22 09:14 java-1.11.0-openjdk-amd64 -> java-11-openjdk-amd64\n",
            "-rw-r--r-- 1 root root 2047 Jul 22 09:14 .java-1.11.0-openjdk-amd64.jinfo\n",
            "drwxr-xr-x 9 root root 4096 Sep 14 13:37 java-11-openjdk-amd64\n",
            "lrwxrwxrwx 1 root root   20 Jul 23 16:13 java-1.8.0-openjdk-amd64 -> java-8-openjdk-amd64\n",
            "-rw-r--r-- 1 root root 2764 Jul 23 16:13 .java-1.8.0-openjdk-amd64.jinfo\n",
            "drwxr-xr-x 7 root root 4096 Sep 19 18:20 java-8-openjdk-amd64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciar uma sessão local\n",
        "from pyspark.sql import SparkSession\n",
        "#sc = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "spark = SparkSession.builder.appName(\"Introducao\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "NTPouiDc_cA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify SparkContext\n",
        "print(spark)\n",
        "\n",
        "#Print Spark version\n",
        "print(spark.version)\n"
      ],
      "metadata": {
        "id": "8yuuhMdOFtAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "CSrl4TU4GErI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listar o catálogo Spark\n",
        "print(spark.catalog.listTables())\n"
      ],
      "metadata": {
        "id": "HLKYkFs2GeWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la ./"
      ],
      "metadata": {
        "id": "GPA1OE0ALfWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando arquivo flights\n",
        "arquivo = \"./sample_data/flights_small.csv\"\n",
        "flights = spark\\\n",
        "          .read.format(\"csv\")\\\n",
        "          .option(\"inferSchema\", \"True\")\\\n",
        "          .option(\"header\", \"True\")\\\n",
        "          .csv(arquivo)\n"
      ],
      "metadata": {
        "id": "54G53C2lG5Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o shape do pyspark dataframe\n",
        "print((flights.count(), len(flights.columns)))"
      ],
      "metadata": {
        "id": "m638SLBDMhfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights.show(10)"
      ],
      "metadata": {
        "id": "oeGM64FWMhpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights.printSchema()"
      ],
      "metadata": {
        "id": "wYLosixJM7qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "PIejphkLM7s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights = flights.\\\n",
        "          withColumn(\"new_air_time\", col(\"air_time\").cast(\"integer\")).drop(\"air_time\")"
      ],
      "metadata": {
        "id": "-A5pQSz-M7wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights.printSchema()"
      ],
      "metadata": {
        "id": "drEssWiyVRzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomeando colunas\n",
        "flights = flights.withColumnRenamed(\"new_air_time\", \"air_time\")"
      ],
      "metadata": {
        "id": "KbeZqnhbU-3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Removendo colunas de um dataframe pySpark   -->   flights = flights.drop(\"new_air_time\")"
      ],
      "metadata": {
        "id": "NFGv09HDWbXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights.show(10)"
      ],
      "metadata": {
        "id": "XX9fCHlcXqgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Registrando o dataframe em uma view temporária\n",
        "flights.createOrReplaceTempView(\"flights\")\n",
        "\n",
        "query = \"FROM flights SELECT * LIMIT 10\"\n",
        "\n",
        "# Selecionando as primeiras 10 linhas\n",
        "flights10 = spark.sql(query)\n",
        "\n",
        "# Imprimindo o resultado\n",
        "flights10.show()\n"
      ],
      "metadata": {
        "id": "NygXQLPlYDUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Registrando o dataframe como view global\n",
        "flights.createOrReplaceGlobalTempView(\"flights\")\n",
        "\n",
        "# A visão temporária global flights fica vinculada ao banco de dados preservado pelo sistema 'global_temp'\n",
        "spark.sql(\"SELECT * FROM global_temp.flights LIMIT 10\").show()\n"
      ],
      "metadata": {
        "id": "q-dJA5rBYDXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# usando GROUP BY\n",
        "query = \"SELECT origin, dest, COUNT(*) as N FROM flights GROUP BY origin, dest\"\n",
        "\n",
        "# Executando a query\n",
        "flight_counts = spark.sql(query)\n",
        "\n",
        "flight_counts.show(10)"
      ],
      "metadata": {
        "id": "3I3khNsaYDa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo o resultado pyspark para pandas\n",
        "import pandas as pd\n",
        "df = flight_counts.toPandas()\n",
        "df.head()\n",
        "\n",
        "\n",
        "# Convertendo a tabela inteira de pyspark para pandas\n",
        "dfpd = flights.toPandas()\n",
        "dfpd.head()"
      ],
      "metadata": {
        "id": "AmIF-FBXaJ6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# incluindo nova coluna para registrar o tempo de voo em horas\n",
        "flights = flights.withColumn(\"Durantion_hrs\", flights.air_time / 60)\n",
        "\n",
        "flights.show(10)"
      ],
      "metadata": {
        "id": "X30ioMR-a9e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights = flights.withColumnRenamed(\"Durantion_hrs\", \"air_time_hrs\")\n",
        "flights.show(10)"
      ],
      "metadata": {
        "id": "A2I-O1s-a9ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionando um conjunto de colunas do dataset\n",
        "selected1 = flights.select(\"tailnum\", \"origin\", \"dest\")\n",
        "selected1.show(10)"
      ],
      "metadata": {
        "id": "i4v-wMKNccPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrando resultados 1\n",
        "flights.filter(\"air_time > 120\").show()"
      ],
      "metadata": {
        "id": "i0JC93dJccqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrando resultados 2\n",
        "flights.filter(flights.air_time > 120).show(5)"
      ],
      "metadata": {
        "id": "Us8BfCjEcctG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o primeiro filtro\n",
        "filtroA = flights.origin == \"SEA\"\n",
        "\n",
        "# Definindo o segundo filtro\n",
        "filtroB = flights.dest ==\"PDX\"\n",
        "\n",
        "# Filtrando os dados, primeiro pelo filtroA em seguida pelo filtroB\n",
        "selected2 = selected1.filter(filtroA).filter(filtroB)\n",
        "\n",
        "selected2.show()"
      ],
      "metadata": {
        "id": "Gf-q8GNYdn8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregando... Encontrando o voo com maior tempo partindo de Seattle\n",
        "flights.filter(flights.origin == \"SEA\").groupby().max(\"air_time\").show()"
      ],
      "metadata": {
        "id": "GIvPH7YBdn-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregando... Encontrando o voo com a menor distancia partindo de Phoenix\n",
        "flights.filter(flights.origin == \"PDX\").groupby().min(\"distance\").show()"
      ],
      "metadata": {
        "id": "0zSiNGuWdoBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregando... Duração média dos voos da companhia Delta que partem de Seattle\n",
        "flights.filter(flights.carrier == \"DL\").filter(flights.origin == \"SEA\").groupby().avg(\"air_time\").show()"
      ],
      "metadata": {
        "id": "bqoR_G5QgT1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tempo total em horas voadas\n",
        "flights.withColumn(\"duration_hrs\", flights.air_time/60).groupby().sum(\"duration_hrs\").show()"
      ],
      "metadata": {
        "id": "dFTwr_mKgT4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pyspark functions\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "#group by por mes e destino\n",
        "by_month_dest = flights.groupby(\"month\", \"dest\")\n",
        "\n",
        "# Desvio padrão\n",
        "\n",
        "by_month_dest.agg(F.stddev(\"dep_delay\")).show()"
      ],
      "metadata": {
        "id": "oY545UMZgT6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JOIN\n",
        "\n",
        "# Importando o arquivo airports\n",
        "arquivo = \"./sample_data/airports.csv\"\n",
        "airports = spark\\\n",
        "          .read.format(\"csv\")\\\n",
        "          .option(\"inferSchema\", \"True\")\\\n",
        "          .option(\"header\", \"True\")\\\n",
        "          .csv(arquivo)\n"
      ],
      "metadata": {
        "id": "6vED6jX4gT9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airports.show(10)"
      ],
      "metadata": {
        "id": "CVvmrZbOgT_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights.show(10)"
      ],
      "metadata": {
        "id": "C2e6Vd07koyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomenao a coluna FAA\n",
        "airports = airports.withColumnRenamed(\"faa\", \"dest\")"
      ],
      "metadata": {
        "id": "x-c4FYCTjg48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JOIN dos dataframes\n",
        "flights_with_airports = flights.join(airports, on=\"dest\", how=\"leftouter\")"
      ],
      "metadata": {
        "id": "kO6UwzFNjg7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights_with_airports.show()\n"
      ],
      "metadata": {
        "id": "hZbvWHYkjg9u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}